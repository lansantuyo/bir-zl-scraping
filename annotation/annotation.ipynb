{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-13T04:37:31.236625Z",
     "start_time": "2025-05-13T04:37:31.233135Z"
    }
   },
   "source": [
    "from file_manager import MusicFileManager\n",
    "from annotation import main, xls_to_df\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:50:12.104199Z",
     "start_time": "2025-05-13T04:50:11.673348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Example Setup ---\n",
    "data_dir = \"data/\"  # <--- IMPORTANT: SET THIS\n",
    "output_annotations_csv = \"pseudo_annotations.csv\"\n",
    "all_annotations_for_csv = []  # This will hold all annotations from all files\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "files_to_process = [f for f in os.listdir(data_dir) if f.lower().endswith(('.xls', '.xlsx'))]\n",
    "if not files_to_process:\n",
    "    print(f\"No Excel files found in {data_dir}. Please add some files or check the path.\")\n",
    "    # exit() # Optional: exit if no files\n",
    "\n",
    "for filename in files_to_process:\n",
    "    print(f\"\\nProcessing file: {filename}\")\n",
    "    df_excel, sheet_name = xls_to_df(filename, base_dir=data_dir)\n",
    "\n",
    "    if df_excel is not None and sheet_name is not None:\n",
    "        # Reset annotations list for each file if you want separate annotation files per excel\n",
    "        # Or use a global list like all_annotations_for_csv for one big file\n",
    "        # For this example, we use the global all_annotations_for_csv\n",
    "\n",
    "        print(f\"Successfully read sheet '{sheet_name}' from {filename}\")\n",
    "        structured_data = main(\n",
    "            df_excel,\n",
    "            start_row_index=155,\n",
    "            end_row_index=200,\n",
    "            filename_for_ann=filename,\n",
    "            sheetname_for_ann=sheet_name,\n",
    "            annotations_list=all_annotations_for_csv,\n",
    "            debug=True,  # Enable debug prints\n",
    "            debug_location=True,\n",
    "            debug_header=False\n",
    "        )\n",
    "        print(f\"\\n--- Structured Data for {filename} ---\")\n",
    "        print(structured_data.head())\n",
    "        print(\"...\")\n",
    "    else:\n",
    "        print(f\"Could not process DataFrame from {filename}\")"
   ],
   "id": "58ad1f584fa1becc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: RDO No. 1 - Laoag City, Ilocos Norte.xls\n",
      "Successfully read sheet 'Sheet 9 (DO 047-2023)' from RDO No. 1 - Laoag City, Ilocos Norte.xls\n",
      "\n",
      "Running find_location_components starting at df index 155\n",
      "\n",
      "find_location_components: Processing df_row 155 (offset 0/2)\n",
      "\n",
      "find_location_components: Processing df_row 156 (offset 1/2)\n",
      "\n",
      "find_location_components: Processing df_row 157 (offset 2/2)\n",
      "\n",
      "Running find_location_components starting at df index 156\n",
      "\n",
      "find_location_components: Processing df_row 156 (offset 0/2)\n",
      "\n",
      "find_location_components: Processing df_row 157 (offset 1/2)\n",
      "\n",
      "find_location_components: Processing df_row 158 (offset 2/2)\n",
      "\n",
      "Running find_location_components starting at df index 157\n",
      "\n",
      "find_location_components: Processing df_row 157 (offset 0/2)\n",
      "\n",
      "find_location_components: Processing df_row 158 (offset 1/2)\n",
      "\n",
      "find_location_components: Processing df_row 159 (offset 2/2)\n",
      "\n",
      "Running find_location_components starting at df index 158\n",
      "\n",
      "find_location_components: Processing df_row 158 (offset 0/2)\n",
      "\n",
      "find_location_components: Processing df_row 159 (offset 1/2)\n",
      "\n",
      "find_location_components: Processing df_row 160 (offset 2/2)\n",
      "\n",
      "Running find_location_components starting at df index 159\n",
      "\n",
      "find_location_components: Processing df_row 159 (offset 0/2)\n",
      "\n",
      "find_location_components: Processing df_row 160 (offset 1/2)\n",
      "\n",
      "find_location_components: Processing df_row 161 (offset 2/2)\n",
      "\n",
      "Running find_location_components starting at df index 160\n",
      "\n",
      "find_location_components: Processing df_row 160 (offset 0/2)\n",
      "\n",
      "find_location_components: Processing df_row 161 (offset 1/2)\n",
      "\n",
      "find_location_components: Processing df_row 162 (offset 2/2)\n",
      "  Province label match found: ILOCOS NORTE at df_row 162\n",
      "\n",
      "Running find_location_components starting at df index 163\n",
      "\n",
      "find_location_components: Processing df_row 163 (offset 0/2)\n",
      "  City/Municipality label match: LAOAG CITY at df_row 163\n",
      "\n",
      "find_location_components: Processing df_row 164 (offset 1/2)\n",
      "  Barangay/Zone label match: SAN LORENZO (POBLACION) at df_row 164\n",
      "\n",
      "find_location_components: Processing df_row 165 (offset 2/2)\n",
      "\n",
      "Total tables processed: 1\n",
      "\n",
      "--- Structured Data for RDO No. 1 - Laoag City, Ilocos Norte.xls ---\n",
      "       Province City/Municipality                 Barangay  \\\n",
      "0  ILOCOS NORTE        LAOAG CITY  SAN LORENZO (POBLACION)   \n",
      "1  ILOCOS NORTE        LAOAG CITY  SAN LORENZO (POBLACION)   \n",
      "2  ILOCOS NORTE        LAOAG CITY  SAN LORENZO (POBLACION)   \n",
      "3  ILOCOS NORTE        LAOAG CITY  SAN LORENZO (POBLACION)   \n",
      "4  ILOCOS NORTE        LAOAG CITY  SAN LORENZO (POBLACION)   \n",
      "\n",
      "             Street/Subdivision  \\\n",
      "0  P. LAZARO ST. (P BURGOS ST.)   \n",
      "1  P. LAZARO ST. (P BURGOS ST.)   \n",
      "2   GOMBURZA ST. (P ZAMORA ST.)   \n",
      "3                           NaN   \n",
      "4                           NaN   \n",
      "\n",
      "                                           Vicinity Classification   ZV/SQM  \n",
      "0    GOV. AGUEDO AGBAYANI ST(NOVALES ST) - AVILA ST             RR  10000.0  \n",
      "1  GOV. AGUEDO AGBAYANI ST(NOVALES ST)-J P RIZAL ST             RR   7700.0  \n",
      "2    GOV. AGUEDO AGBAYANI ST(NOVALES ST) - RIZAL ST             CR  10200.0  \n",
      "3                                               NaN             RR   8000.0  \n",
      "4              RIZAL ST - GOMBURZA ST(P. ZAMORA ST)             RR   8000.0  \n",
      "...\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:37:57.812234Z",
     "start_time": "2025-05-13T04:37:57.809299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LABEL_LOC_P = \"LOC_P\"\n",
    "LABEL_LOC_C = \"LOC_C\"\n",
    "LABEL_LOC_B = \"LOC_B\"\n",
    "LABEL_HDR = \"HDR\"\n",
    "LABEL_DATA = \"DATA\"\n",
    "LABEL_BLANK = \"BLANK\"\n",
    "LABEL_OTHER = \"OTHER\"\n",
    "LABEL_TITLE = \"TITLE\"  # If you have logic to detect titles, not present in current main\n",
    "LABEL_NOTE = \"NOTE\"  # If you have logic to detect notes, not present in current main"
   ],
   "id": "4b7fa3b4dfc156d6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T04:38:03.764157Z",
     "start_time": "2025-05-13T04:38:01.049667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Write all collected annotations to a single CSV file ---\n",
    "if all_annotations_for_csv:\n",
    "    # Deduplicate annotations (important if rows could be added multiple times by different logic paths)\n",
    "    # A simple way is to convert to list of tuples and then to set and back, based on unique (file, sheet, row_index)\n",
    "    seen_annotations = set()\n",
    "    final_unique_annotations = []\n",
    "    for ann in all_annotations_for_csv:\n",
    "        # Create a unique key for each annotation entry\n",
    "        # Using only row_index for uniqueness *within a sheet*\n",
    "        # For global uniqueness, use (filename, sheetname, row_index)\n",
    "        ann_key = (ann[\"filename\"], ann[\"sheetname\"], ann[\"row_index\"])\n",
    "        if ann_key not in seen_annotations:\n",
    "            final_unique_annotations.append(ann)\n",
    "            seen_annotations.add(ann_key)\n",
    "        else:  # If seen, we might want to update if the new label is more specific, e.g. OTHER -> DATA\n",
    "            # This requires more complex logic, for now, first one wins or last one based on order.\n",
    "            # Let's make it so that more specific labels (not OTHER/BLANK) can overwrite.\n",
    "            # Find existing and update if new is better\n",
    "            for i, existing_ann in enumerate(final_unique_annotations):\n",
    "                if (existing_ann[\"filename\"], existing_ann[\"sheetname\"], existing_ann[\"row_index\"]) == ann_key:\n",
    "                    # Prioritize more specific labels over generic ones\n",
    "                    priority = {LABEL_LOC_P: 5, LABEL_LOC_C: 5, LABEL_LOC_B: 5, LABEL_HDR: 4, LABEL_DATA: 3,\n",
    "                                LABEL_TITLE: 2, LABEL_NOTE: 2, LABEL_BLANK: 1, LABEL_OTHER: 0}\n",
    "                    if priority.get(ann[\"label\"], -1) > priority.get(existing_ann[\"label\"], -1):\n",
    "                        final_unique_annotations[i] = ann  # Update with more specific label\n",
    "                    break\n",
    "\n",
    "    # Sort by filename, sheetname, then row_index for consistent output\n",
    "    final_unique_annotations.sort(key=lambda x: (x[\"filename\"], x[\"sheetname\"], x[\"row_index\"]))\n",
    "\n",
    "    print(f\"\\nWriting {len(final_unique_annotations)} pseudo-annotations to {output_annotations_csv}\")\n",
    "    annotation_df = pd.DataFrame(final_unique_annotations)\n",
    "    annotation_df.to_csv(output_annotations_csv, index=False, quoting=csv.QUOTE_ALL)\n",
    "    print(\"Annotation CSV created successfully.\")\n",
    "else:\n",
    "    print(\"No annotations were generated.\")"
   ],
   "id": "fbfdd4a08b349c40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing 25346 pseudo-annotations to pseudo_annotations.csv\n",
      "Annotation CSV created successfully.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a15c1d789851f574"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
