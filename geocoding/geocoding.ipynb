{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:30:39.814518Z",
     "start_time": "2025-03-02T19:30:39.810598Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1917494c-1f3d-433e-833a-eb6c98ed6da4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Geocoding and Spatial Analysis with H3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd2c3593-08ad-48d4-b320-803ca6cc1561",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:30:40.657372Z",
     "start_time": "2025-03-02T19:30:39.815524Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8a2455b-70d3-487a-9a88-b0800a251026",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import h3\n",
    "import time\n",
    "import folium\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple, List, Optional, Union\n",
    "from datetime import datetime\n",
    "from branca.colormap import LinearColormap\n",
    "import os\n",
    "from IPython.display import display\n",
    "import json\n",
    "import os\n",
    "import hashlib\n",
    "from typing import Dict, Any, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:30:40.661023Z",
     "start_time": "2025-03-02T19:30:40.657876Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c65242a-e606-4685-84d0-a95424e1de01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:30:40.668313Z",
     "start_time": "2025-03-02T19:30:40.661023Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "632167a7-6dda-428f-82ba-e0c734e076e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Configuration Parameters\n",
    "class Config:\n",
    "    # API configuration\n",
    "    API_KEY = \"\"  # Replace with your Google Maps API key\n",
    "    API_RATE_LIMIT_DELAY = 0.2  # Seconds between API calls (Google standard tier = 50 QPS)\n",
    "    \n",
    "    # File paths\n",
    "    INPUT_FILE = \"geocoding/Output/Updated_RDO No. 50 - South Makati.xlsx\"\n",
    "    OUTPUT_DIR = \"geocoding/Output\"\n",
    "    \n",
    "    # H3 configuration\n",
    "    H3_RESOLUTION = 9  # Values 0-15: higher = more precise but more hexagons\n",
    "    # Resolution 9 ≈ cells with ~0.1 km² area (174m edge length)\n",
    "    \n",
    "    # Visualization settings\n",
    "    MAP_COLORS = ['#fee5d9', '#fcae91', '#fb6a4a', '#cb181d']  # Light to dark red\n",
    "    MAP_ZOOM = 14\n",
    "    \n",
    "    # Processing options\n",
    "    SAMPLE_SIZE = None  # Set to a number (e.g., 5) to process only a sample of records\n",
    "    RETRY_COUNT = 3  # Number of retries for failed geocoding\n",
    "    RETRY_DELAY = 1  # Seconds to wait between retries\n",
    "\n",
    "# Ensure output directory exists\n",
    "if not os.path.exists(Config.OUTPUT_DIR):\n",
    "    os.makedirs(Config.OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:30:40.674164Z",
     "start_time": "2025-03-02T19:30:40.669318Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b355d82f-dcc3-4972-8c5e-045c1abb628c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Configuration loaded. Using H3 resolution {Config.H3_RESOLUTION} (~{174 * (2**(9-Config.H3_RESOLUTION)):.0f}m edge length)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e67a0944-7d6c-43d5-b991-ab4cfd1fb885",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:30:40.681168Z",
     "start_time": "2025-03-02T19:30:40.674164Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ce3a6da-65d4-47a1-a19c-0b528999f291",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_data(filepath: str, sample_size: Optional[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the address data from Excel file with optional sampling\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the Excel file\n",
    "        sample_size: Number of random samples to take (None = all data)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing the address data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(filepath)\n",
    "        print(f\"Data loaded successfully from {filepath}\")\n",
    "        print(f\"Total records: {len(df)}\")\n",
    "        \n",
    "        # Clean up column names\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        # Take a sample if specified\n",
    "        if sample_size and sample_size < len(df):\n",
    "            df = df.sample(n=sample_size, random_state=42)\n",
    "            print(f\"Sampled {sample_size} records for processing\")\n",
    "            \n",
    "        # Basic data validation\n",
    "        required_cols = ['Street/Subdivision', 'Barangay', 'City/Municipality']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"Warning: Missing required columns: {', '.join(missing_cols)}\")\n",
    "            \n",
    "        # Convert ZV/SQM to numeric if it exists\n",
    "        if 'ZV/SQM' in df.columns:\n",
    "            df['ZV/SQM'] = pd.to_numeric(df['ZV/SQM'], errors='coerce')\n",
    "            print(f\"ZV/SQM values range: ₱{df['ZV/SQM'].min():,.2f} - ₱{df['ZV/SQM'].max():,.2f}\")\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {str(e)}\")\n",
    "        # Return empty DataFrame with expected columns to prevent errors\n",
    "        return pd.DataFrame(columns=['Street/Subdivision', 'Barangay', 'City/Municipality', 'Province'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:30:41.070192Z",
     "start_time": "2025-03-02T19:30:40.682269Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d242261-9279-410c-88c0-8cf2be2d89e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = load_data(Config.INPUT_FILE, Config.SAMPLE_SIZE)\n",
    "\n",
    "# Display a preview of the data\n",
    "if not df.empty:\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"No data to process. Please check the input file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38a86071-f1df-4f02-9588-345aff264e9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Geocoding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:30:41.075687Z",
     "start_time": "2025-03-02T19:30:41.071198Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55ab6971-efa2-4363-beeb-a21fe1823e06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def format_address(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Format address components into a single string optimized for geocoding\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row containing address components\n",
    "        \n",
    "    Returns:\n",
    "        Formatted address string\n",
    "    \"\"\"\n",
    "    components = []\n",
    "    \n",
    "    # Add building/house number if available\n",
    "    if pd.notna(row.get('Building/House No.')):\n",
    "        components.append(str(row['Building/House No.']).strip())\n",
    "    \n",
    "    # Add street/subdivision\n",
    "    if pd.notna(row.get('Street/Subdivision')):\n",
    "        components.append(str(row['Street/Subdivision']).strip())\n",
    "    \n",
    "    # Add barangay (important for Philippine addresses)\n",
    "    if pd.notna(row.get('Barangay')):\n",
    "        components.append(f\"Barangay {str(row['Barangay']).strip()}\")\n",
    "    \n",
    "    # Add city/municipality\n",
    "    if pd.notna(row.get('City/Municipality')):\n",
    "        components.append(str(row['City/Municipality']).strip())\n",
    "    \n",
    "    # Add province\n",
    "    if pd.notna(row.get('Province')):\n",
    "        components.append(str(row['Province']).strip())\n",
    "    \n",
    "    # Always add country for better results\n",
    "    components.append('Philippines')\n",
    "    \n",
    "    # Join with commas for standard geocoding format\n",
    "    return \", \".join(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:30:41.084102Z",
     "start_time": "2025-03-02T19:30:41.076694Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7472cb4-4b5e-4d64-ba25-3e305730b02e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class GeocodingCache:\n",
    "    \"\"\"Cache for storing geocoding results to minimize API calls\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir: str = \"cache\", cache_file: str = \"geocoding_cache.json\"):\n",
    "        \"\"\"\n",
    "        Initialize the geocoding cache\n",
    "        \n",
    "        Args:\n",
    "            cache_dir: Directory to store the cache file\n",
    "            cache_file: Name of the cache file\n",
    "        \"\"\"\n",
    "        self.cache_dir = cache_dir\n",
    "        self.cache_file = os.path.join(cache_dir, cache_file)\n",
    "        self.cache = {}\n",
    "        self._load_cache()\n",
    "    \n",
    "    def _load_cache(self) -> None:\n",
    "        \"\"\"Load the cache from file if it exists\"\"\"\n",
    "        if not os.path.exists(self.cache_dir):\n",
    "            os.makedirs(self.cache_dir)\n",
    "            \n",
    "        if os.path.exists(self.cache_file):\n",
    "            try:\n",
    "                with open(self.cache_file, 'r') as f:\n",
    "                    self.cache = json.load(f)\n",
    "                print(f\"Loaded {len(self.cache)} cached geocoding results\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading cache: {str(e)}\")\n",
    "                self.cache = {}\n",
    "    \n",
    "    def _save_cache(self) -> None:\n",
    "        \"\"\"Save the current cache to file\"\"\"\n",
    "        try:\n",
    "            with open(self.cache_file, 'w') as f:\n",
    "                json.dump(self.cache, f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving cache: {str(e)}\")\n",
    "    \n",
    "    def _get_cache_key(self, address: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate a cache key for an address\n",
    "        \n",
    "        Args:\n",
    "            address: The address to generate a key for\n",
    "            \n",
    "        Returns:\n",
    "            A hash string to use as cache key\n",
    "        \"\"\"\n",
    "        # Normalize the address (lowercase, remove extra spaces)\n",
    "        normalized = ' '.join(address.lower().split())\n",
    "        # Create a hash for the normalized address\n",
    "        return hashlib.md5(normalized.encode('utf-8')).hexdigest()\n",
    "    \n",
    "    def get(self, address: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Get cached geocoding result for an address\n",
    "        \n",
    "        Args:\n",
    "            address: The address to look up\n",
    "            \n",
    "        Returns:\n",
    "            Cached result or None if not in cache\n",
    "        \"\"\"\n",
    "        key = self._get_cache_key(address)\n",
    "        return self.cache.get(key)\n",
    "    \n",
    "    def set(self, address: str, result: Dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Store geocoding result in cache\n",
    "        \n",
    "        Args:\n",
    "            address: The address being geocoded\n",
    "            result: The geocoding result to cache\n",
    "        \"\"\"\n",
    "        key = self._get_cache_key(address)\n",
    "        self.cache[key] = result\n",
    "        # Save to disk periodically (every 10 new entries)\n",
    "        if len(self.cache) % 10 == 0:\n",
    "            self._save_cache()\n",
    "    \n",
    "    def close(self) -> None:\n",
    "        \"\"\"Save cache and clean up resources\"\"\"\n",
    "        self._save_cache()\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:30:41.091477Z",
     "start_time": "2025-03-02T19:30:41.085109Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8816bf1a-3310-472e-b5a5-de91efd10619",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Update the geocode_address function to use the cache\n",
    "def geocode_address(\n",
    "    address: str, \n",
    "    api_key: str,\n",
    "    cache: GeocodingCache,\n",
    "    region: str = 'ph', \n",
    "    retry_count: int = 3, \n",
    "    retry_delay: int = 1\n",
    ") -> Tuple[float, float, Dict]:\n",
    "    \"\"\"\n",
    "    Geocode address using Google's Geocoding API with caching\n",
    "    \n",
    "    Args:\n",
    "        address: Formatted address string\n",
    "        api_key: Google Maps API key\n",
    "        cache: GeocodingCache instance\n",
    "        region: Region bias (default: 'ph' for Philippines)\n",
    "        retry_count: Number of retries for failed requests\n",
    "        retry_delay: Seconds to wait between retries\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (latitude, longitude, full response data)\n",
    "        \n",
    "    Raises:\n",
    "        Exception: If geocoding fails after all retries\n",
    "    \"\"\"\n",
    "    # Check cache first\n",
    "    cached_result = cache.get(address)\n",
    "    if cached_result:\n",
    "        print(f\"Cache hit: {address}\")\n",
    "        location = cached_result['geometry']['location']\n",
    "        return location['lat'], location['lng'], cached_result\n",
    "    \n",
    "    # If not in cache, proceed with API call\n",
    "    print(f\"Cache miss: {address}\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"API key is required. Please set Config.API_KEY.\")\n",
    "        \n",
    "    url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    params = {\n",
    "        'address': address,\n",
    "        'key': api_key,\n",
    "        'region': region\n",
    "    }\n",
    "    \n",
    "    # Implement retry logic for resilience\n",
    "    for attempt in range(retry_count):\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            data = response.json()\n",
    "            \n",
    "            if data['status'] == 'OK':\n",
    "                result = data['results'][0]\n",
    "                # Store in cache\n",
    "                cache.set(address, result)\n",
    "                \n",
    "                location = result['geometry']['location']\n",
    "                return location['lat'], location['lng'], result\n",
    "                \n",
    "            elif data['status'] == 'ZERO_RESULTS':\n",
    "                raise Exception(f\"No results found for address: {address}\")\n",
    "                \n",
    "            elif data['status'] in ['OVER_QUERY_LIMIT', 'OVER_DAILY_LIMIT']:\n",
    "                print(f\"API quota exceeded. Status: {data['status']}\")\n",
    "                # Wait longer for rate limit errors\n",
    "                time.sleep(retry_delay * 2)\n",
    "                \n",
    "            else:\n",
    "                print(f\"Geocoding error: {data['status']} (Attempt {attempt+1}/{retry_count})\")\n",
    "                time.sleep(retry_delay)\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed: {str(e)} (Attempt {attempt+1}/{retry_count})\")\n",
    "            time.sleep(retry_delay)\n",
    "    \n",
    "    # If we've exhausted all retries\n",
    "    raise Exception(f\"Geocoding failed after {retry_count} attempts for address: {address}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:30:41.097543Z",
     "start_time": "2025-03-02T19:30:41.092484Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fd2d764-b5ee-4c47-90a2-d92ef207e06a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_h3_index(lat: float, lng: float, resolution: int = 9) -> str:\n",
    "    \"\"\"\n",
    "    Convert coordinates to H3 index at the specified resolution\n",
    "    \n",
    "    Args:\n",
    "        lat: Latitude\n",
    "        lng: Longitude\n",
    "        resolution: H3 resolution (0-15, higher = more precise)\n",
    "        \n",
    "    Returns:\n",
    "        H3 index as string\n",
    "    \"\"\"\n",
    "    return h3.latlng_to_cell(lat, lng, resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:30:41.103399Z",
     "start_time": "2025-03-02T19:30:41.098548Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf32c036-11f4-451b-99ac-ed1e30f2b724",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def h3_hexagon_to_coordinates(h3_address: str) -> List[List[float]]:\n",
    "    \"\"\"\n",
    "    Convert H3 address to boundary coordinates for plotting\n",
    "    \n",
    "    Args:\n",
    "        h3_address: H3 index\n",
    "        \n",
    "    Returns:\n",
    "        List of [lat, lng] coordinates representing the hexagon boundary\n",
    "    \"\"\"\n",
    "    # Get the boundary vertices\n",
    "    boundary = h3.cell_to_boundary(h3_address)\n",
    "    # Folium expects coordinates in lat,lng format\n",
    "    return [[coord[0], coord[1]] for coord in boundary]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd7718e0-9df8-418d-8593-83ba8cab777c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:30:41.111403Z",
     "start_time": "2025-03-02T19:30:41.103399Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb12b13a-c377-4d07-b29d-e23ae3eecda4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def process_addresses(df: pd.DataFrame, api_key: str, h3_resolution: int, \n",
    "                     delay: float = 0.2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process all addresses in the DataFrame with progress tracking and caching\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing address data\n",
    "        api_key: Google Maps API key\n",
    "        h3_resolution: H3 resolution to use\n",
    "        delay: Seconds to wait between API calls\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with original data and geocoding results\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        print(\"No data to process.\")\n",
    "        return df\n",
    "        \n",
    "    results = []\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    cache_hits = 0\n",
    "    \n",
    "    # Start time for estimating completion\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Initialize cache\n",
    "    with GeocodingCache() as cache:\n",
    "        for idx, row in df.iterrows():\n",
    "            try:\n",
    "                # Format the address\n",
    "                address = format_address(row)\n",
    "                \n",
    "                # Calculate and display progress\n",
    "                progress = (idx + 1) / len(df) * 100\n",
    "                elapsed = time.time() - start_time\n",
    "                addresses_per_second = (idx + 1) / elapsed if elapsed > 0 else 0\n",
    "                est_remaining = (len(df) - (idx + 1)) / addresses_per_second if addresses_per_second > 0 else 0\n",
    "                \n",
    "                print(f\"[{progress:.1f}%] Processing {idx + 1}/{len(df)}: {address}\")\n",
    "                if idx > 0:\n",
    "                    print(f\"  Speed: {addresses_per_second:.2f} addr/sec, Est. remaining: {est_remaining/60:.1f} min\")\n",
    "                \n",
    "                # Check if this was a cache hit before adding delay\n",
    "                is_cache_hit = cache.get(address) is not None\n",
    "                if is_cache_hit:\n",
    "                    cache_hits += 1\n",
    "                else:\n",
    "                    # Only add delay for actual API calls\n",
    "                    time.sleep(delay)\n",
    "                \n",
    "                # Geocode the address with cache\n",
    "                lat, lng, google_data = geocode_address(\n",
    "                    address, \n",
    "                    api_key,\n",
    "                    cache,\n",
    "                    retry_count=Config.RETRY_COUNT, \n",
    "                    retry_delay=Config.RETRY_DELAY\n",
    "                )\n",
    "                \n",
    "                # Get H3 index\n",
    "                h3_index = get_h3_index(lat, lng, h3_resolution)\n",
    "                \n",
    "                # Store results\n",
    "                results.append({\n",
    "                    'original_address': address,\n",
    "                    'latitude': lat,\n",
    "                    'longitude': lng,\n",
    "                    'h3_index': h3_index,\n",
    "                    'google_formatted_address': google_data['formatted_address'],\n",
    "                    'google_place_id': google_data.get('place_id', ''),\n",
    "                    'google_location_type': google_data['geometry']['location_type'],\n",
    "                    'processing_status': 'success',\n",
    "                    'from_cache': is_cache_hit\n",
    "                })\n",
    "                \n",
    "                successful += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {idx}: {str(e)}\")\n",
    "                \n",
    "                # Store error information\n",
    "                results.append({\n",
    "                    'original_address': format_address(row) if 'Street/Subdivision' in row else \"Address formatting failed\",\n",
    "                    'processing_status': 'failed',\n",
    "                    'error_message': str(e)\n",
    "                })\n",
    "                \n",
    "                failed += 1\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Merge with original data\n",
    "    if not results_df.empty:\n",
    "        output_df = pd.concat([df.reset_index(drop=True), results_df.reset_index(drop=True)], axis=1)\n",
    "    else:\n",
    "        output_df = df.copy()\n",
    "        output_df['processing_status'] = 'no_results'\n",
    "    \n",
    "    # Print processing summary\n",
    "    print(\"\\nProcessing Summary:\")\n",
    "    print(f\"Total addresses processed: {len(output_df)}\")\n",
    "    print(f\"Successful geocoding: {successful} ({successful/len(output_df)*100:.1f}%)\")\n",
    "    print(f\"Failed geocoding: {failed} ({failed/len(output_df)*100:.1f}%)\")\n",
    "    print(f\"Cache hits: {cache_hits} ({cache_hits/len(output_df)*100:.1f}%)\")\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:38:10.529907Z",
     "start_time": "2025-03-02T19:30:41.112498Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d75d491-a380-4e61-83be-1b74114911f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Replace the original process_addresses call with this:\n",
    "if Config.API_KEY and not df.empty:\n",
    "    print(\"Starting geocoding process with caching...\")\n",
    "    output_df = process_addresses(df, Config.API_KEY, Config.H3_RESOLUTION, Config.API_RATE_LIMIT_DELAY)\n",
    "    \n",
    "    # Save results to Excel\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    output_file = os.path.join(Config.OUTPUT_DIR, f\"geocoded_addresses_{timestamp}.xlsx\")\n",
    "    output_df.to_excel(output_file, index=False)\n",
    "    print(f\"\\nProcessing complete. Results saved to {output_file}\")\n",
    "    \n",
    "    # Basic analysis of results\n",
    "    if 'google_location_type' in output_df.columns:\n",
    "        print(\"\\nLocation type distribution:\")\n",
    "        print(output_df['google_location_type'].value_counts())\n",
    "else:\n",
    "    print(\"Skipping geocoding process. Either API key is missing or no data to process.\")\n",
    "    # For testing visualization without geocoding, we can use the original df\n",
    "    output_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9a1d226-934c-48ea-885f-79674286fc8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:38:10.540913Z",
     "start_time": "2025-03-02T19:38:10.530916Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f13721e-73b4-4270-a0d5-07a88ff2d773",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_zone_value_map(df: pd.DataFrame, output_filename: str = 'zoning_map.html') -> folium.Map:\n",
    "    \"\"\"\n",
    "    Create a map visualization of zone values using H3 hexagons\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with geocoded addresses and zone values\n",
    "        output_filename: Name of HTML file to save the map\n",
    "        \n",
    "    Returns:\n",
    "        Folium Map object\n",
    "    \"\"\"\n",
    "    # Check required columns\n",
    "    required_cols = ['latitude', 'longitude', 'h3_index', 'ZV/SQM']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"Warning: Cannot create map. Missing columns: {', '.join(missing_cols)}\")\n",
    "        # Create an empty map centered on Philippines\n",
    "        return folium.Map(location=[14.5995, 120.9842], zoom_start=11)\n",
    "    \n",
    "    # Clean data: Remove rows with missing required values\n",
    "    map_df = df.dropna(subset=required_cols)\n",
    "    \n",
    "    if map_df.empty:\n",
    "        print(\"Warning: No valid data for map visualization\")\n",
    "        return folium.Map(location=[14.5995, 120.9842], zoom_start=11)\n",
    "    \n",
    "    # Sort by ZV/SQM for better coloring\n",
    "    map_df = map_df.sort_values('ZV/SQM')\n",
    "    \n",
    "    # Create map centered on data points\n",
    "    center_lat = map_df['latitude'].mean()\n",
    "    center_lng = map_df['longitude'].mean()\n",
    "    m = folium.Map(location=[center_lat, center_lng], zoom_start=Config.MAP_ZOOM)\n",
    "    \n",
    "    # Calculate quantiles for better color distribution\n",
    "    q_25 = map_df['ZV/SQM'].quantile(0.25)\n",
    "    q_50 = map_df['ZV/SQM'].quantile(0.50)\n",
    "    q_75 = map_df['ZV/SQM'].quantile(0.75)\n",
    "    max_value = map_df['ZV/SQM'].max()\n",
    "    min_value = map_df['ZV/SQM'].min()\n",
    "    \n",
    "    # Create color map\n",
    "    colormap = LinearColormap(\n",
    "        colors=Config.MAP_COLORS,\n",
    "        vmin=min_value,\n",
    "        vmax=max_value,\n",
    "        caption='Zone Value per Square Meter (PHP)'\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store hexagons by H3 index (to avoid duplicates)\n",
    "    hexagon_dict = {}\n",
    "    \n",
    "    # Process each row\n",
    "    for idx, row in map_df.iterrows():\n",
    "        try:\n",
    "            # Get hexagon coordinates\n",
    "            hex_coordinates = h3_hexagon_to_coordinates(row['h3_index'])\n",
    "            \n",
    "            # Store the highest ZV/SQM value for each hexagon\n",
    "            if (row['h3_index'] not in hexagon_dict or \n",
    "                hexagon_dict[row['h3_index']]['value'] < row['ZV/SQM']):\n",
    "                \n",
    "                # Create popup text with all useful information\n",
    "                popup_text = f\"\"\"\n",
    "                <b>Address:</b> {row.get('google_formatted_address', row.get('original_address', 'N/A'))}<br>\n",
    "                <b>Zone Value:</b> ₱{row['ZV/SQM']:,.2f}/sqm<br>\n",
    "                \"\"\"\n",
    "                \n",
    "                # Add classification if available\n",
    "                if 'Classification' in row and pd.notna(row['Classification']):\n",
    "                    popup_text += f\"<b>Classification:</b> {row['Classification']}<br>\"\n",
    "                \n",
    "                # Add barangay if available\n",
    "                if 'Barangay' in row and pd.notna(row['Barangay']):\n",
    "                    popup_text += f\"<b>Barangay:</b> {row['Barangay']}<br>\"\n",
    "                \n",
    "                # Store hexagon data\n",
    "                hexagon_dict[row['h3_index']] = {\n",
    "                    'coordinates': hex_coordinates,\n",
    "                    'value': row['ZV/SQM'],\n",
    "                    'popup_text': popup_text\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing map row {idx}: {str(e)}\")\n",
    "    \n",
    "    # Add hexagons to the map\n",
    "    for h3_index, data in hexagon_dict.items():\n",
    "        try:\n",
    "            # Get color based on value\n",
    "            color = colormap(data['value'])\n",
    "            \n",
    "            # Add polygon to map\n",
    "            folium.Polygon(\n",
    "                locations=data['coordinates'],\n",
    "                color='black',\n",
    "                weight=1,\n",
    "                fill=True,\n",
    "                fill_color=color,\n",
    "                fill_opacity=0.7,\n",
    "                popup=folium.Popup(data['popup_text'], max_width=300)\n",
    "            ).add_to(m)\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding hexagon {h3_index}: {str(e)}\")\n",
    "    \n",
    "    # Add the colormap to the map\n",
    "    colormap.add_to(m)\n",
    "    \n",
    "    # Add layer control\n",
    "    folium.LayerControl().add_to(m)\n",
    "    \n",
    "    # Save the map\n",
    "    output_path = os.path.join(Config.OUTPUT_DIR, output_filename)\n",
    "    m.save(output_path)\n",
    "    print(f\"Map saved to {output_path}\")\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\nZone Value Statistics:\")\n",
    "    print(map_df['ZV/SQM'].describe())\n",
    "    \n",
    "    print(\"\\nValue Ranges:\")\n",
    "    print(f\"0-25th percentile: ₱{q_25:,.2f}/sqm\")\n",
    "    print(f\"25-50th percentile: ₱{q_50:,.2f}/sqm\")\n",
    "    print(f\"50-75th percentile: ₱{q_75:,.2f}/sqm\")\n",
    "    print(f\"75-100th percentile: ₱{max_value:,.2f}/sqm\")\n",
    "    \n",
    "    # Print classification distribution if available\n",
    "    if 'Classification' in map_df.columns:\n",
    "        print(\"\\nClassification Distribution:\")\n",
    "        print(map_df['Classification'].value_counts())\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:38:10.893639Z",
     "start_time": "2025-03-02T19:38:10.541418Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9bc60a9-4764-455f-8b06-fec8435e0268",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create visualization if data is available\n",
    "if 'ZV/SQM' in output_df.columns:\n",
    "    zoning_map = create_zone_value_map(output_df, 'makati_zoning_map.html')\n",
    "    display(zoning_map)\n",
    "else:\n",
    "    print(\"Cannot create visualization: ZV/SQM column missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecbd856d-2fb0-4fc2-aa90-29d9c0dc7983",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Advanced Analysis (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:38:10.899694Z",
     "start_time": "2025-03-02T19:38:10.894645Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b9b2eca-1a15-43a4-af40-6675bc5ff95b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def analyze_zone_data(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Perform additional analysis on zone value data\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with geocoded addresses and zone values\n",
    "    \"\"\"\n",
    "    if 'ZV/SQM' not in df.columns or 'Barangay' not in df.columns:\n",
    "        print(\"Cannot perform analysis: Required columns missing\")\n",
    "        return\n",
    "    \n",
    "    # Clean data\n",
    "    analysis_df = df.dropna(subset=['ZV/SQM', 'Barangay'])\n",
    "    \n",
    "    if analysis_df.empty:\n",
    "        print(\"No valid data for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Analysis by Barangay\n",
    "    print(\"\\n=== Analysis by Barangay ===\")\n",
    "    barangay_stats = analysis_df.groupby('Barangay')['ZV/SQM'].agg([\n",
    "        'count', 'min', 'max', 'mean', 'median', 'std'\n",
    "    ]).sort_values('median', ascending=False)\n",
    "    \n",
    "    # Format currency values\n",
    "    for col in ['min', 'max', 'mean', 'median']:\n",
    "        barangay_stats[col] = barangay_stats[col].apply(lambda x: f\"₱{x:,.2f}\")\n",
    "    \n",
    "    print(barangay_stats)\n",
    "    \n",
    "    # Analysis by Classification (if available)\n",
    "    if 'Classification' in analysis_df.columns:\n",
    "        print(\"\\n=== Analysis by Classification ===\")\n",
    "        class_stats = analysis_df.groupby('Classification')['ZV/SQM'].agg([\n",
    "            'count', 'min', 'max', 'mean', 'median', 'std'\n",
    "        ]).sort_values('median', ascending=False)\n",
    "        \n",
    "        # Format currency values\n",
    "        for col in ['min', 'max', 'mean', 'median']:\n",
    "            class_stats[col] = class_stats[col].apply(lambda x: f\"₱{x:,.2f}\")\n",
    "        \n",
    "        print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T19:38:10.915740Z",
     "start_time": "2025-03-02T19:38:10.900701Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7ee84f4-7658-4ee5-973e-ea69c990c137",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run additional analysis if data is available\n",
    "if not output_df.empty and 'ZV/SQM' in output_df.columns:\n",
    "    analyze_zone_data(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T20:30:50.895201Z",
     "start_time": "2025-03-02T20:30:50.884203Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "804b515f-6ad9-45f9-be9d-e0d1acf0b248",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T20:34:29.024146Z",
     "start_time": "2025-03-02T20:34:28.051589Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01ecd304-162d-4a71-b86f-f3a8ebce98f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Set the style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['figure.figsize'] = [12, 10]\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "\n",
    "# Helper function to format currency values\n",
    "def format_currency(x, pos):\n",
    "    return f'₱{x/1000:.0f}k'\n",
    "\n",
    "# Create barangay data\n",
    "barangay_data = {\n",
    "    'Barangay': [\n",
    "        'POST PROPER NORTHSIDE', 'FORBES PARK VILLAGE', 'POST PROPER SOUTHSIDE', \n",
    "        'DASMARIÑAS VILLAGE', 'URDANETA VILLAGE', 'PINAGKAISAHAN', \n",
    "        'GUADALUPE NUEVO', 'BEL-AIR (SALCEDO VILLAGE)', 'WEST REMBO',\n",
    "        'SOUTH CEMBO', 'EAST REMBO', 'PITOGO', 'CEMBO', 'COMEMBO', 'PEMBO', 'RIZAL'\n",
    "    ],\n",
    "    'count': [270, 38, 783, 43, 75, 52, 65, 500, 93, 87, 108, 44, 34, 45, 131, 133],\n",
    "    'min': [200000, 154000, 98000, 275000, 0, 0, 0, 0, 83000, 103000, 75000, 101000, 70000, 65000, 59000, 47000],\n",
    "    'max': [900000, 414000, 900000, 425000, 929000, 300000, 300000, 940000, 150000, 250000, 180000, 214000, 200000, 138000, 123000, 79000],\n",
    "    'median': [500000, 338000, 300000, 300000, 222000, 123000, 120000, 115000, 115000, 113000, 110000, 108000, 80000, 65000, 60000, 47000]\n",
    "}\n",
    "\n",
    "# Create classification data\n",
    "classification_data = {\n",
    "    'Classification': ['CR', 'CC', 'RC', 'RR', 'X', 'PS'],\n",
    "    'count': [839, 246, 205, 878, 77, 256],\n",
    "    'min': [0, 0, 0, 0, 0, 0],\n",
    "    'max': [940000, 423000, 550000, 350000, 575000, 385000],\n",
    "    'median': [500000, 180000, 160000, 120000, 113000, 98000],\n",
    "    'full_name': ['Commercial Regular', 'Commercial Center', 'Residential Commercial', \n",
    "                 'Residential Regular', 'Special Zone', 'Public Service']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T20:36:27.743950Z",
     "start_time": "2025-03-02T20:36:27.735951Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fafc7db2-640c-45fc-b0a3-7367ee1c10d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Set the style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Helper function to format currency values\n",
    "def format_currency(x, pos):\n",
    "    return f'₱{x/1000:.0f}k'\n",
    "\n",
    "# Create barangay data\n",
    "barangay_data = {\n",
    "    'Barangay': [\n",
    "        'POST PROPER NORTHSIDE', 'FORBES PARK VILLAGE', 'POST PROPER SOUTHSIDE', \n",
    "        'DASMARIÑAS VILLAGE', 'URDANETA VILLAGE', 'PINAGKAISAHAN', \n",
    "        'GUADALUPE NUEVO', 'BEL-AIR (SALCEDO VILLAGE)', 'WEST REMBO',\n",
    "        'SOUTH CEMBO', 'EAST REMBO', 'PITOGO', 'CEMBO', 'COMEMBO', 'PEMBO', 'RIZAL'\n",
    "    ],\n",
    "    'count': [270, 38, 783, 43, 75, 52, 65, 500, 93, 87, 108, 44, 34, 45, 131, 133],\n",
    "    'min': [200000, 154000, 98000, 275000, 0, 0, 0, 0, 83000, 103000, 75000, 101000, 70000, 65000, 59000, 47000],\n",
    "    'max': [900000, 414000, 900000, 425000, 929000, 300000, 300000, 940000, 150000, 250000, 180000, 214000, 200000, 138000, 123000, 79000],\n",
    "    'median': [500000, 338000, 300000, 300000, 222000, 123000, 120000, 115000, 115000, 113000, 110000, 108000, 80000, 65000, 60000, 47000]\n",
    "}\n",
    "\n",
    "# Create classification data\n",
    "classification_data = {\n",
    "    'Classification': ['CR', 'CC', 'RC', 'RR', 'X', 'PS'],\n",
    "    'count': [839, 246, 205, 878, 77, 256],\n",
    "    'min': [0, 0, 0, 0, 0, 0],\n",
    "    'max': [940000, 423000, 550000, 350000, 575000, 385000],\n",
    "    'median': [500000, 180000, 160000, 120000, 113000, 98000],\n",
    "    'full_name': ['Commercial Regular', 'Commercial Center', 'Residential Commercial', \n",
    "                 'Residential Regular', 'Special Zone', 'Public Service']\n",
    "}\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_barangay = pd.DataFrame(barangay_data)\n",
    "df_classification = pd.DataFrame(classification_data)\n",
    "\n",
    "# Sort barangay data by median value (descending)\n",
    "df_barangay = df_barangay.sort_values('median', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T20:36:31.534070Z",
     "start_time": "2025-03-02T20:36:31.310532Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57ba8d7b-1b93-4747-ae06-b17082d356bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# PLOT 1: Bar Chart for Median Values by Barangay\n",
    "# --------------------------------------------------------------------------\n",
    "plt.figure(figsize=(12, 10))\n",
    "bars = sns.barplot(x='median', y='Barangay', data=df_barangay, palette='Blues_d')\n",
    "plt.title('Median Zone Values by Barangay', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Median Zone Value (₱/sqm)', fontsize=12)\n",
    "plt.ylabel('Barangay', fontsize=12)\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(format_currency))\n",
    "\n",
    "# Add value annotations\n",
    "for i, bar in enumerate(bars.patches):\n",
    "    value = df_barangay.iloc[i]['median']\n",
    "    plt.text(bar.get_width() + 20000, bar.get_y() + bar.get_height()/2, \n",
    "             f'₱{value:,.0f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T20:36:36.666607Z",
     "start_time": "2025-03-02T20:36:36.513843Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "702b1140-f7ca-4d56-8a03-58c5739106ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# PLOT 2: Bar Chart for Median Values by Classification\n",
    "# --------------------------------------------------------------------------\n",
    "plt.figure(figsize=(10, 8))\n",
    "class_colors = plt.cm.viridis(np.linspace(0, 0.9, len(df_classification)))\n",
    "bars2 = sns.barplot(x='Classification', y='median', data=df_classification, palette=class_colors)\n",
    "plt.title('Median Zone Values by Classification', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Classification', fontsize=12)\n",
    "plt.ylabel('Median Zone Value (₱/sqm)', fontsize=12)\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(format_currency))\n",
    "\n",
    "# Add value annotations\n",
    "for i, bar in enumerate(bars2.patches):\n",
    "    value = df_classification.iloc[i]['median']\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 20000, \n",
    "             f'₱{value:,.0f}', ha='center', fontsize=10)\n",
    "\n",
    "# Add classification full names as a legend\n",
    "handles = [plt.Rectangle((0,0),1,1, color=class_colors[i]) for i in range(len(df_classification))]\n",
    "labels = [f\"{row['Classification']} - {row['full_name']}\" for _, row in df_classification.iterrows()]\n",
    "plt.legend(handles, labels, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T20:36:44.123231Z",
     "start_time": "2025-03-02T20:36:44.006582Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c4acdd3-f98c-4ea9-b0d9-cfcf025ea4db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# PLOT 3: Pie Chart for Property Distribution by Classification\n",
    "# --------------------------------------------------------------------------\n",
    "plt.figure(figsize=(10, 8))\n",
    "explode = [0.1] + [0] * (len(df_classification) - 1)  # Explode first slice (CR)\n",
    "wedges, texts, autotexts = plt.pie(\n",
    "    df_classification['count'], \n",
    "    autopct='%1.1f%%', \n",
    "    explode=explode,\n",
    "    colors=class_colors,\n",
    "    shadow=True, \n",
    "    startangle=90\n",
    ")\n",
    "plt.title('Property Distribution by Classification', fontweight='bold', fontsize=16)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "\n",
    "# Create custom legend\n",
    "legend_labels = [f\"{row['Classification']} - {row['full_name']} ({row['count']} properties)\" \n",
    "                for _, row in df_classification.iterrows()]\n",
    "plt.legend(wedges, legend_labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T20:36:52.138414Z",
     "start_time": "2025-03-02T20:36:52.043277Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e79ed1f-c44f-497d-9e49-5a08f55c4026",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# PLOT 4: Key Insights Textbox\n",
    "# --------------------------------------------------------------------------\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.axis('off')\n",
    "insights_text = \"\"\"\n",
    "KEY INSIGHTS:\n",
    "• Premium Areas: POST PROPER NORTHSIDE, FORBES PARK VILLAGE, and DASMARIÑAS VILLAGE have the highest median values (₱300,000+/sqm).\n",
    "• Commercial Impact: Commercial Regular (CR) properties command the highest values (₱500,000/sqm median), 2.8× higher than Residential Regular (RR).\n",
    "• Property Distribution: Residential Regular (RR) and Commercial Regular (CR) properties make up the majority (68%) of all properties.\n",
    "• Value Range: There's a 10× difference in median values between the highest (POST PROPER NORTHSIDE: ₱500,000) and lowest (RIZAL: ₱47,000) barangays.\n",
    "\"\"\"\n",
    "plt.text(0.5, 0.5, insights_text, ha='center', va='center', fontsize=14, \n",
    "         bbox=dict(facecolor='lightblue', alpha=0.1, boxstyle='round,pad=1'))\n",
    "\n",
    "plt.title('MAKATI CITY ZONE VALUE ANALYSIS - KEY INSIGHTS', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T20:36:55.008673Z",
     "start_time": "2025-03-02T20:36:54.859621Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "966ac1fd-2ad8-49da-8c39-06cdbe039330",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# PLOT 5: Range Comparison (Bonus Visualization)\n",
    "# --------------------------------------------------------------------------\n",
    "plt.figure(figsize=(12, 10))\n",
    "y_pos = np.arange(len(df_barangay))\n",
    "\n",
    "# Create custom colors that are lighter at the top and darker at bottom\n",
    "colors = plt.cm.Blues(np.linspace(0.3, 0.9, len(df_barangay)))\n",
    "\n",
    "# Plot median values as bars\n",
    "bars = plt.barh(y_pos, df_barangay['median'], color=colors)\n",
    "\n",
    "# Add error bars from min to max\n",
    "plt.errorbar(df_barangay['median'], y_pos, \n",
    "             xerr=[[df_barangay['median'] - df_barangay['min']], [df_barangay['max'] - df_barangay['median']]], \n",
    "             fmt='o', color='black', capsize=5)\n",
    "\n",
    "# Customize the plot\n",
    "plt.yticks(y_pos, df_barangay['Barangay'])\n",
    "plt.xlabel('Zone Value (₱/sqm)')\n",
    "plt.title('Zone Value Ranges by Barangay', fontsize=16, fontweight='bold')\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(format_currency))\n",
    "\n",
    "# Add range annotations\n",
    "for i, bar in enumerate(bars):\n",
    "    min_val = df_barangay.iloc[i]['min']\n",
    "    max_val = df_barangay.iloc[i]['max']\n",
    "    plt.text(bar.get_width() + 10000, bar.get_y() + bar.get_height()/2, \n",
    "             f'₱{min_val:,.0f} - ₱{max_val:,.0f}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e8048cd-89e5-4e53-8997-cf155c03fa58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "geocoding",
   "widgets": {}
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
